\documentclass[14pt]{extarticle}
\usepackage{researchPaper}
\usepackage{outlines}

\title{EE 560 Cheat Sheet}
\begin{document}
	\maketitle
	
	\begin{outline}		
		\1	Basic Definitions
			\2	$P[A] = lim_{n \rightarrow \infty} \frac{n(A)}{n}$
			\2	$P[A] = \frac{N_A}{N}$
			\2	Axioms of Probability
				\3	$P[A] \ge 0$
				\3	$P[\Omega] = 1$
				\3	$P[\bigcup_{i=1}^{\infty} A_i] = \sum_{i=1}^{\infty} P[A_i]$
					\4	$A_i \cap A_j = \emptyset~\forall~i,j~i \ne j$
			\2	Probability Space
				\3	$\Omega$ The Sample Space:	Set of all possible outcomes of an experiment
					\4	Given a set with $N$ elmentary outcomes, there can be $2^N$ events in F
					\4	$2^N$ field of events is called the power set
				\3	$F$ the field of events.  Subsets of sample space which are assigned probabilities
					\4	$\emptyset \in F$
					\4	$\Omega \in F$
					\4	$A \in F$ and $B \in F \rightarrow A\cup B \in F$ and $A \cap B \in F$
					\4	$A \in F \rightarrow \bar{A} \in F$
				\3	$P$ A probability function which assigns a real number to each event in F
		\1	Set Theory
			\2	Set is a collection of objects, with no repetition
			\2	Set membership
				\3	$a \in A$ a is in the set A
				\3	$d \notin A$ d is not in the set A
				\3	$\emptyset = \{\}$ is the empty or null set
			\2	Types of Sets
				\3	Universal set (or Sample Space) is the set of all elements
				\3	Subset
					\4	$A \subset B$ iff $x \in A \rightarrow x \in B$, $x \in B$ does not mean $x \in A$
					\4	$\emptyset \subset A \subset B \subset \Omega$
					\4	$A \subset B$ and $B \subset C \rightarrow A \subset C$
				\3	Equality between sets: $A = B$ iff $A \subset B$ and $B \subset A$
			\2	Set Operations
				\3	Union:	$x \in A \cup B$ iff $x \in A$ or $x \in B$
					\4	$A \cup B = B \cup A$
					\4	$(A \cup B) \cup C = A \cup (B \cup C)$
					\4	if $A \subset B \rightarrow A \cup B = B$
					\4	$A \cup A = A$
					\4	$A \cup \emptyset = A$
					\4	$A \cup \Omega = \Omega$
				\3	Intersection
					\4	$x \in A \cap B$ iff $x \in A$ and $x \in B$
					\4	Commutative and Associative
					\4	$A \cap (B \cup C) = (A \cap B) \cup (A \cap C)$
					\4	$A \subset B \rightarrow A \cap B = A$
					\4	$A \cap \emptyset = \emptyset$
					\4	$A \cap \Omega = A$
			\2	Mutual Exclusion: $A \cap B = \emptyset$
			\2	Independence:	$P[A \cap B] = P[A]P[B]$ DIFFERENT FROM MUTUAL EXCLUSION
			\2	De-Morgan's Law
				\3	$\bar{A \cup B} = \bar{A} \cap \bar{B}$
				\3	$\bar{A \cap B} = \bar{A} \cup \bar{B}$
			\2	Inclusion-Exclusion
				\3	Size of a union of sets can be written as:
					\4	Sum of Individual sets
					\4	Minus sum over all pairs of sizes of intersection
					\4	plus the sum over all triples of the sizes of their intersections
			\2	Probability Results
				\3	$P[A] = P[A \cup \emptyset] \rightarrow P[\emptyset] = 0$
				\3	$P[A] = 1 - P[\bar{A}] \le 1$
				\3	$A \subset B \rightarrow P[A] \le P[B]$
				\3	$P[A \cup B] = P[A] + P[B] - P[A \cap B]$
		\1	Conditional Probability
			\2	$P[A | B] = \frac{P[A \cap B]}{P[B]}$
		\1	Baye's Rule
			\2	$P[A | B] = \frac{P[B|A] P[A]}{P[B]}$
				\3	Technically $P[A | B] = \frac{P[B | A] = P[A]}{\sum_i P[B|A_i]P[A_i]}$
			\2	$P[A |B]$ is the posterior (knowledge after we know B)
			\2	Conditioning on independent events does not help the probability
		\1	Combinatorics
			\2	Ordered subset or Sampling WITHOUT Replacement
				\3	Permutations	
				\3	Size $n$, with $r$ subsets
				\3	$P = \frac{n!}{(n - r)!}$
			\2	Unordered Subset 
				\3	Combinations
				\3	$C = \binom{n}{r} = \frac{n!}{(n-r)!r!}$
				\3	$r$ heads in $n$ coin tosses
				\3	$\sum_{r = 0}^n \binom{n}{r} = 2^n$
			\2	Birthday Problem
				\3	Ratio of sampling with replacement to sampling without replacement
				\3	$P[Shared] = 1 - \frac{\Pi_{k = 1}^r (365 - k + 1)}{365^r}$
			\2	Occupancy Problem
				\3	Number of distributions of $r$ balls in $n$ cells
				\3	Balls are distinguishable
					\4	$P = n^r$
				\3	Balls are not distinguishable
					\4	$P = \binom{n+r-1}{r}$
		\1	Borel Cantelli Theorem
			\2	$P[A]$ is the probability of infinite number of successes
			\2	$\sum_{n=1}^{\infty} P_n < \infty \rightarrow P[A] = 0$
			\2	$\sum_{n=1}^{\infty} P_n = \infty \rightarrow P[A] = 1$
		\1	Random Variables
			\2	$X : \Omega \rightarrow \mathbb{R}$
			\2	$P[X = x] := P[s : X(s) = x]$
			\2	$P[X \le x] := P[s : X(s) \le x]$
			\2	Probability Mass Function (PMF)
				\3	$P[x] \ge 0~\forall~x$
				\3	$\sum_{x \in \Omega_X}P[x] = 1$
				\3	$B \subset \Omega_X \rightarrow P[B] = \sum_{x \in B}P[x]$
		\1	Types of Random Variables
			\2	Bernoulli RV
				\3	$P[x] = \begin{cases} 1 - p & x = 0 \\ p & x = 1   \end{cases}$
				\3	Coin flip, bit transmit, success and failure
			\2	Geometric RV
				\3	$P[x] = p(1-p)^{x-1}$
				\3	Number of Bernoulli trials until and including the first success
				\3	Toss a coin, probabilty of $x$ tosses until the first heads
			\2	Binomial RV
				\3	$P[x] = \binom{n}{x}p^x(1-p)^{n-x}$
				\3	Flip a coin $n$ times, probability $x$ is the number of heads
			\2	Negative Binomial
				\3	$P[x] = \binom{x-1}{k-1}p^k(1-p)^{x-k},~x=k,k+1,...$
				\3	number of bernoulli trials until and including the $k$th success
			\2	Discrete Uniform Distribution
				\3	$P[x] = \frac{1}{b - a + 1}$
				\3	Uniformly distributed between $[a,b]$
			\2	Poisson
				\3	$P[x] = \frac{e^{-\lambda}\lambda^x}{x!}$
				\3	$\lambda = np$ is the mean
				\3	Poisson approximates the binomial when the number of trials is large
						and the probability of success is small

	\end{outline}
\end{document}


















