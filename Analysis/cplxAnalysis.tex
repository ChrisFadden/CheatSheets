\documentclass[14pt]{extarticle}
\usepackage{researchPaper}
\usepackage{outlines}
\def\Definition{{\color{blue} \textbf{Definition:} }}
\def\Theorem{{\color{red} \textbf{Theorem:} }}

\title{Complex Analysis Cheat Sheet}
\begin{document}
\maketitle

%Conway A function of single complex variable
\begin{outline}		
\section*{Analytic Functions}
	\1	\Definition \textbf{Riemann Sphere}
		\2	Extension of the Complex numbers to $\infty$, 
				$\mathbb{C}_{\infty} = \mathbb{C} \cup \infty$
		\2	Represent the complex numbers as the unit sphere
				$S = \{(x_1,x_2,x_3) \in \mathbb{R}^3~:~x_1^2 + x_2^2 + x_3^2 = 1\}$
			\3	$\mathbb{C} = \{(x_1,x_2,0)~:~x_1,x_2 \in \mathbb{R}\}$
			\3	$x_1 = \frac{z + \bar{z}}{\abs{z}^2 + 1}$
			\3	$x_2 = \frac{-i(z - \bar{z})}{\abs{z}^2 + 1}$
			\3	$x_3 = \frac{\abs{z}^2 - 1}{\abs{z}^2 + 1}$
			\3	$z = \frac{x_1 + ix_2}{1 - x_3}$
			\3	$d(z_1,z_2) = \frac{2\abs{z_1 - z_2}}{[(1 + \abs{z_1}^2)(1 + \abs{z_2}^2)]^{\frac{1}{2}}}$
				\4	$z_1,~z_2 \in \mathbb{C}$

	\1	\Definition \textbf{Region of Convergence}
		\2	Given any powerseries $\sum_{n=0}^{\infty} a_n(z - b)^n$
		\2	$\frac{1}{R} = lim~sup~\abs{a_n}^{\frac{1}{n}}$
			\3	If $\abs{z - b} < R$ the series converges absolutely
			\3	If $\abs{z - b} > R$ the series diverges
			\3	If $0 < r < R$ the series converges uniformly on $\{z~:~\abs{z} \le r\}$
			\3	$R = lim \abs{\frac{a_n}{a_{n+1}}}$ if the limit exists
	\1	\Definition \textbf{Analytic Function}
		\2	If $U \in \mathbb{C}$ is an open set, and $f~:~U \rightarrow \mathbb{C}$
				then $f$ is differentiable at a point $a \in U$ if
				$\lim_{h \rightarrow 0} \frac{f(a + h) - f(a)}{h}$ exists
		\2	A function $f~:~U \rightarrow \mathbb{C}$ is analytic if $f$ is 
				continuously differentiable
	\1	\Definition \textbf{Branch Cuts}
		\2	If $G$ is an open connected set in $\mathbb{C}$ and $f~:~G \rightarrow \mathbb{C}$
				is a continuous function such that $z = e^{f(z)}~\forall~z \in G$ then
				$f$ is a branch of the logarithm
	\1	\Theorem \textbf{Branches of Logarithm}
		\2	If $G \subset \mathbb{C}$ is open and connected, and $f$ is a branch
				of $log(z)$ on $G$ then all branches of $log(z)$ can be written
				$f(z) + 2\pi k i,~k \in \mathbb{Z}$
	\1	\Definition	\textbf{Principal Branchi of the Logarithm}
		\2	Set $G = \mathbb{C} - \{z~:~Re(z) \le 0\}$
		\2	$f(z) = log(\abs{z}) + i \text{Arg}(z)$
		\2	$f(z)$ is the principal branch of the logarithm
			\3	Uniquely represented on the set $G$
	\1	\Theorem	\textbf{Derivative of Branches of Logarithm}
		\2	A branch of the logarithm function is analyic and its derivative is $z^{-1}$
	\1	\Definition \textbf{Cauchy Riemann Equations}
		\2	$f(z) = u(x,y) + iv(x,y)$ 
		\2	$f(z)$ is analytic iff $\pd{u}{x} = \pd{v}{y}$ and $\pd{u}{y} = -\pd{v}{x}$
	\1	\Definition \textbf{Conformal Mapping}
		\2	Conformal maps preserve angles locally
		\2	$f(z)$ is conformal iff $f(z)$ is analytic and $f(z) \ne 0~\forall~z \in U$
	\1	\Definition \textbf{Mobius Transformation}
		\2	$S(z) = \frac{az + b}{cz + d}$ and $ad - bc \ne 0$
		\2	$S$ is a composition of translations, dilations, and inversion
	\1	\Theorem	\textbf{Mobius Transformation maps circles to circles}
\section*{Complex Integration}
	\1	\Definition \textbf{Bounded Variation}
		\2	$\gamma~:~[a,b] \rightarrow \mathbb{C}$ is piecewise smooth then $\gamma$
				if of bounded variation nad $V(\gamma) = \int_a^b \abs{\gamma'(t)} dt$
	\1	\Definition \textbf{Complex Integral}
		\2	Let $\gamma~:~[a,b] \rightarrow \mathbb{C}$ be of bounded variation and
				suppose that $f~:~[a,b] \rightarrow \mathbb{C}$ is continuous.  Then 
				there is a complex number $I$ such that 
				$I = \int_a^b f d\gamma = \int_a^b f(t) d\gamma(t)$
	\1	\Theorem \textbf{Parameterized Complex Integral}
		\2	If $\gamma$ is piecewise continuous smooth and $f~:~[a,b] \rightarrow \mathbb{C}$
				is continuous then $\int_a^b f d\gamma = \int_a^b f(t) \gamma'(t) dt$
	\1	\Definition \textbf{Line Integral}
		\2	If $\gamma~:~[a,b] \rightarrow \mathbb{C}$ has bounded variation, 
				and $f$ is defined and continuous on the trace of $\gamma$, then the 
				line integral of $f$ along $\gamma$ is
				$\int_{\gamma} f = \int_{\gamma}f(z) dz = \int_a^bf(\gamma(t)) d\gamma(t)$
	\1	\Theorem \textbf{Cauchy's Integral Formula}
		\2	For open set $U \subset \mathbb{C}$, $f~:~U \rightarrow \mathbb{C}$ analytic,
				and the closed disk $D = \{z~:~\abs{z - z_0} \le r\} \subseteq U$, with
				$\gamma = \partial D$, then for every $a \in \text{int}(D)$:
		\2	$f(a) = \frac{1}{2 \pi i}\oint_{\gamma} \frac{f(z)}{z - a}dz$
		\2	$f^{(n)}(a) = \frac{n!}{2\pi i}\oint_{\gamma} \frac{f(z)}{(z - a)^{n+1}}dz$
	\1	\Theorem \textbf{Laurent Series}
		\2	If $f$ is analytic on $B(b;R)$ then $f(z) = \sum_{n=-\infty}^{\infty}a_n(z - b)^n$
				for $\abs{z - b} < R$ and $a_n = \frac{1}{n!}f^{(n)}(b)$
	\1	\Theorem \textbf{Cauchy's Estimate}
		\2	Let $f$ be analytic in $B(b;R)$ and $\abs{f(z)} \le M~\forall~z \in B(b;R)$,
				then $\abs{f^{(n)}(b)} \le \frac{n!M}{R^n}$
	\1	\Definition \textbf{Zeros of an Analytic Function}
		\2	If $f~:~U \rightarrow \mathbb{C}$ is analytic and $a \in G$ satisfies
				$f(a) = 0$ then $a$ is a zero of multiplicity $m \ge 1$ if there is
				an analytic function $g~:~U \rightarrow \mathbb{C}$ such that 
				$f(z) = (z - a)^mg(z)$ where $g(a) \ne 0$
	\1	\Definition \textbf{Entire function}
		\2	An entire function is defined and analytic over the entire complex plane
				$\mathbb{C}$
		\2	This is also known as an integral function
	\1	\Theorem \textbf{Power Series of Entire Functions}
		\2	If $f$ is an entire function, then $f(z) = \sum_{n=0}^{\infty} a_n z^n$
		\2	$R = \infty$
	\1	\Theorem \textbf{Liouville's Theorem}
		\2	If $f$ is a bounded entire function than $f$ is constant
	\1	\Theorem \textbf{Fundamental Theorem of Algebra}
		\2	If $p(z)$ is a non-constant polynomial then there is a complex number
				$a$ with $p(a) = 0$
	\1	\Theorem	\textbf{Analytic Functions that are Zero}
		\2	The following are equivalent statements:
			\3	$f \equiv 0$
			\3	$\exists~a \in U~:~f^{(n)}(a) = 0~\forall~n \ge 0$
			\3	$\{z \in U~:~f(z) = 0\}$ has a limit point in $U$
		\2	If $f$ and $g$ are analytic on $U$, then $f \equiv g$ iff
				$\{z\in U~:~f(z) = g(z)\}$ has a limit point in $U$
		\2	Each zero of $f$ has finite mulitiplicity
	\1	\Theorem	\textbf{Maximum Modulus Theorem}
		\2	If $f~:~U \rightarrow \mathbb{C}$ is an analytic function such that
				$\abs{f(a)} \ge \abs{f(z)}~\forall~z \in U$ then $f$ is constant
		\2	For an analytic function, it cannot exhibit true local maximum within
				its domain
	\1	\Theorem	\textbf{Morera's Theorem}
		\2	Let $U$ be a region and $f~:~U \rightarrow \mathbb{C}$ be a continuous
				function such that $\int_T f = 0$ for every triangular path $T \in U$;
				then $f$ is analytic in $U$
	\1	\Theorem	\textbf{Cauchy's Intgral Theorem}
		\2	If $U$ is simply connected, then $\oint_{\gamma} f(z) dz = 0$ for every closed
				rectifiable curve and every analytic function $f$
	\1	\Theorem	\textbf{Open Mapping Theorem}
		\2	If $f~:~U \rightarrow \mathbb{C}$ is a non-constant analytic function,
				then $f$ is an open map
		\2	$f$ sends open subsets of $U$ to open subsets of $\mathbb{C}$
	\1	\Theorem	\textbf{Goursat's Theorem}
		\2	Let $f~:~U \rightarrow \mathbb{C}$ be a differentiable function on open
				set $U$, then $f$ is analytic on $U$
\section*{Singularities}
	\1	\Definition \textbf{Isolated Singularity}
		\2	A function $f$ has an isolated singularity at $z = a$ if there is an 
				$R > 0$ such that $f$ is defined and analytic in $B(a;R) \setminus \{a\}$
				but not in $B(a;R)$.  
		\2	The point $a$ is a removable singularity if there is an analytic function
				$g~:~B(a;R) \rightarrow \mathbb{C}$ such that $g(z) = f(z)$ for 
				$0 < \abs{z - a} < R$.
	\1	\Theorem \textbf{Removable Singularity}
		\2	If $f$ has an isolated singularity at $a$ then the point $z = a$ is
				a removable singularity iff $\lim_{z \rightarrow a} (z-a)f(z) = 0$
	\1	\Definition \textbf{Pole}
		\2	If $z = a$ is an isolated singularity, then $a$ is a pole of $f$ if
				$\lim_{z \rightarrow a} \abs{f(z)} = \infty$
	\1	\Definition \textbf{Essential Singularity}
		\2	If an isolated singularity is neither a removable singularity nor a pole,
				it is called an essential singularity
	\1	\Definition \textbf{Order of Poles}
		\2	If $f$ has a pole at $z = a$ and $m$ is the smallest positive integer
				such taht $f(z)(z - a)^m$ has a removable singularity at $z = a$ then
				$f$ has a pole of order $m$ at $z = a$
	\1	\Definition \textbf{Absolute Convergence}
		\2	A series $\sum_{n=-\infty}^{\infty} z_n$ is absolutely convergent if 
				both $\sum_{n=0}^{\infty}z_n$ and $z={n=1}^{\infty} z_{-n}$ are absolutely
				convergent.
	\1	\Definition \textbf{Annulus}
		\2	For $0 \le R_1 < R_2 \le \infty$, $a \in \mathbb{C}$, 
				$ann(a;R_1,R_2) = \{z~:~R_1 < \abs{z - a} < R_2\}$
	\1	\Definition \textbf{Laurent Series}
		\2	$f(z) = \sum_{n=-\infty}^{\infty} a_n (z - a)^n$
		\2	$f$ must be analytic in the annulus $ann(a;R_1,R_2)$
		\2	The convergence is absolute and uniform over $ann(a;r_1,r_2)$, 
				with $R_1 < r_1 < r_2 < R_2$
		\2	$a_n = \frac{1}{2\pi i} \int_{\gamma} \frac{f(z)}{(z - a)^{n+1}}dz$
			\3	$\gamma$ is the circle $\abs{z - a} = r$, $\forall~r~:R_1 < r < R_2$
		\2	The Laurent Series is unique
	\1	\Theorem \textbf{Classification of Singularities using Laurent Series}
		\2	Let $z = a$ be an isolated singularity of $f$, and let
				$f(z) = \sum_{n=-\infty}^{\infty} a_n(z - a)^n$ be its Laurent expansion
				in $ann(a;0,R)$ Then:
				\3	$z = a$ is a removable singularity iff $a_n = 0$ for $n \le -1$
				\3	$z = a$ is a pole of order $m$ iff $a_{-m} \ne 0$ and $a_n = 0$ for $n \le -(m+1)$
				\3	$z = a$ is an essential singularity iff $a_n \ne 0$ for infinitely
						many negative integers $n$
	\1	\Theorem \textbf{Casorati-Weierstrass Theorem}
		\2	If $f$ has an essential singularity at $z = a$ then $\forall~\delta > 0$,
				$f[ann(a;0,\delta)] = \mathbb{C}$
		\2	As $z$ approaches $a$ (an essential singularity) the values of $f(z)$
				come arbitrarily close to every complex number
	\1	\Definition \textbf{Residue}
		\2	Let $f$ have an isolated singularity at $z = a$ and let $f$ have a 
				Laurent Series
		\2	The residue of $f$ at $z = a$ is the coefficient $a_{-1}$
		\2	The residue is denoted $Res(f;a) = a_{-1}$
	\1	\Theorem	\textbf{Cauchy's Residue Theorem}
		\2	Let $f$ be analytic in $U$ except for the isolated singularities 
				$a_1,a_2,...,a_n$.  If $\gamma$ is a closed rectifiable curve in $U$
				which does not pass through any of the points $a_k$ and if 
				$\gamma \approx 0$ in $U$ then:
		\2	$\frac{1}{2\pi i}\int_{\gamma} f = \sum_{k=1}^n I(\gamma;a_k) Res(f;a_k)$
			\3	$I$ is the winding number of $\gamma$ around $a_k$
	\1	\Theorem \textbf{Residue Theorem with Poles of Order m}
		\2	Suppose $f$ has a pole of order $m$ at $z = a$ and $g(z) = (z-a)^mf(z)$
		\2	$Res(f;a) = \frac{1}{(m-1)!}g^{m-1}(a)$
	\1	\Definition \textbf{Meromorphic Function}
		\2	If $U$ is open, and $f$ is a function defined and analytic in $U$ except
				for poles, then $f$ is a meromorphic function on $U$
	\1	\Theorem \textbf{Cauchy's Argument Principle}
		\2	Let $f$ be meromorphic on $U$ with poles $p_1,p_2,...,p_m$ and zeros
				$z_1,z_2,...,z_n$ counted with multiplicity.  If $\gamma$ is a closed
				rectifiable curve in $U$ with $\gamma \approx 0$ and not passing through
				$p_1,p_2,...,p_m$ or $z_1,...,z_n$ then:
		\2	$\frac{1}{2\pi i} \int_{\gamma} \frac{f'(z)}{f(z)}dz = 
					\sum_{k=1}^n I(\gamma;z_k) - \sum_{j=1}^n I(\gamma;p_j)$
	\1	\Theorem	\textbf{Inverse Function using Argument Principle}
		\2	Let $f$ be analytic on $U$ containing $\bar{B}(a;R)$ and suppose that
				$f$ is injective on $\bar{B}(a;R)$.  If $\Omega = f[B(a;R)]$ and $\gamma$
				is the circle $\abs{z - a} = R$ then $f^{-1}(\omega)$ is defined 
				$\forall~\omega~\in \Omega$ by
		\2	$f^{-1}(\omega) = \frac{1}{2\pi i}\int_{\gamma}\frac{zf'(z)}{f(z) - \omega}dz$
	\1	\Theorem \textbf{Rouche's Theorem}
		\2	$f$ and $g$ are meromorphic in a neighborhood $\bar{B}(a;R)$ with no zeros
				or poles on the circle $\gamma = \{z~:~\abs{z - a} = R\}$.  If $Z_f$,$Z_g$,
				$P_f$,$P_g$ are the number of zeros and poles of $f$ and $g$ inside $\gamma$,
				counting multiplicties and if $\abs{f(z) + g(z)} < \abs{f(z)} + \abs{g(z)}$
				on $\gamma$ then $Z_f - P_f = Z_g - P_g$
\section*{Maximum Modulus Theorem}
\end{outline}
\end{document}


